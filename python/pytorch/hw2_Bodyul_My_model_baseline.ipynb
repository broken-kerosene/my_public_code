{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 1,
    "id": "kr9vAeEQlRVG"
   },
   "source": [
    "# Домашнее задание 2. Классификация изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": 4,
    "id": "LKcSNj4tlRVK"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "\n",
    "import os\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "#torch.manual_seed(SEED)\n",
    "#torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# You may add any imports you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты поиска пполезных материалов\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html  <br>\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html <br>\n",
    "https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RytEDW0ylRVN"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uSqSsFg4lRVN"
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "        \n",
    "    def __init__(self, data_dir, transform):\n",
    "        # YOUR CODE\n",
    "        self.train_root = data_dir\n",
    "        self.transforms = transform\n",
    "        self.classes = []\n",
    "        self.images = []      \n",
    "               \n",
    "        for img_class in os.listdir(self.train_root):\n",
    "            img = os.listdir((os.path.join(self.train_root, img_class)))\n",
    "            for i in img:\n",
    "                self.images.append(self.train_root +'/'+ img_class + '/' + i)\n",
    "                self.classes.append(img_class)      \n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # YOUR CODE\n",
    "        img = Image.open(self.images[idx]).convert(\"RGB\")\n",
    "        item = self.transforms(img)\n",
    "        return item, int(self.classes[idx][6:])\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # YOUR CODE\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 5,
    "id": "QEdDQtHdlRVO"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "        #transforms.ColorJitter(hue=.05, saturation=.05), # делает обучение более стабильным\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomEqualize(),\n",
    "        #transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)),\n",
    "        #transforms.RandomRotation(degrees=(-90, 90)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform2 = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_transforms = transform\n",
    "val_transforms = transform2\n",
    "\n",
    "# YOU CAN DEFINE AUGMENTATIONS HERE\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(r\"dataset/train\", transform=train_transforms)\n",
    "val_dataset = MyDataset(r\"dataset/val\", transform=val_transforms)\n",
    "\n",
    "batch = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch, num_workers=4) # TRAIN DATALOADER WHICH YOU CONSTRUCT\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, shuffle=True, batch_size=batch, num_workers=4) # VAL DATALOADER WHICH YOU CONSTRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": 6,
    "id": "mrg4Yj0VlRVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "# Just very simple sanity checks\n",
    "assert isinstance(train_dataset[0], tuple)\n",
    "assert len(train_dataset[0]) == 2\n",
    "assert isinstance(train_dataset[1][1], int)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RlSlmyjlRVP"
   },
   "source": [
    "### Вспомогательные функции, реализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": 7,
    "id": "yYG2-Cq8lRVQ"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, epoch_index, device=\"cuda:0\"):\n",
    "    model.train()\n",
    "    \n",
    "    # YOUR CODE\n",
    "    # TRAIN YOUR MODEL HERE\n",
    "    running_loss = 0\n",
    "    num = 0\n",
    "    res_loss = []\n",
    "    for x_, y_ in tqdm(train_dataloader):\n",
    "        x_train, y_train = x_.to(device), y_.to(device) # перенос вычислений на GPU\n",
    "        \n",
    "        y_pred = model(x_train) # делаем предсказание\n",
    "        \n",
    "        loss = criterion(y_pred, y_train) \n",
    "        loss.backward()\n",
    "        optimizer.step() # делаем шаг SGD\n",
    "        optimizer.zero_grad() # зануляем градиенты\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        res_loss.append(loss.item())\n",
    "        num += 1\n",
    "        if num % 250 == 249:    # \n",
    "            #print(f'[{epoch_index}, {num + 1:5d}] loss: {running_loss / 250:.3f}')\n",
    "            running_loss = 0.0\n",
    "    return np.mean(res_loss)\n",
    "\n",
    "def predict(model, val_dataloader, criterion, device=\"cuda:0\"):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    # YOUR CODE\n",
    "    # PREDICT FOR EVERY ELEMENT OF THE VAL DATALOADER AND RETURN CORRESPONDING LISTS\n",
    "    losses = []\n",
    "    true_classes = []\n",
    "    predicted_classes = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x_, y_ in tqdm(val_dataloader):\n",
    "            x_test, y_test = x_.to(device), y_.to(device) # перенос вычислений на GPU           \n",
    "            y_pred = model(x_test)\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            predicted_classes.extend(predicted.cpu().numpy().tolist())\n",
    "            true_classes.extend(y_test.cpu().numpy().tolist())\n",
    "            \n",
    "            total += y_test.size(0)\n",
    "            correct += (predicted == y_test).sum().item()\n",
    "       \n",
    "    return np.mean(losses), predicted_classes, true_classes\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler=None, device=\"cuda:0\", n_epochs=10):\n",
    "    model.to(device)\n",
    "    _, predicted, true = predict(model, val_dataloader, criterion, device=\"cuda:0\")\n",
    "    best_acc = accuracy_score(predicted, true)\n",
    "    print(f\"Начальная точность: {100 * best_acc:.2f} %\" )\n",
    "    for epoch in (range(1, n_epochs+1)):\n",
    "        # YOUR CODE\n",
    "        train_loss = train_one_epoch(model, train_dataloader, criterion, optimizer, epoch, device=\"cuda:0\")\n",
    "        if True or epoch % 2 == 1: \n",
    "            valid_loss, predicted, true = predict(model, val_dataloader, criterion, device=\"cuda:0\")\n",
    "            accuracy = accuracy_score(predicted, true)\n",
    "            print(f\"Эпоха: {epoch};\\t train loss: {train_loss:.3f};\\t valid loss: {valid_loss:.3f};\\t Точность: {100 * accuracy:.2f} %\")\n",
    "            if best_acc < accuracy:\n",
    "                best_acc = accuracy\n",
    "                torch.save(model, \"model/MyModel_baseline_best.pth\")\n",
    "                torch.save(model.state_dict(), \"model/My_model_baseline_best_w.pt\")\n",
    "                \n",
    "        if scheduler != None:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxR3gfcilRVW"
   },
   "source": [
    "### Обучение модели, запуски экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(6, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): ReLU()\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU()\n",
       "    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU()\n",
       "    (23): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU()\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU()\n",
       "    (30): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU()\n",
       "    (33): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU()\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (37): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (38): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU()\n",
       "    (40): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU()\n",
       "    (43): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU()\n",
       "    (46): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = nn.Sequential()\n",
    "              \n",
    "        self.linear_layers = nn.Sequential()\n",
    "\n",
    "         # Антецедент распространения\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "model = torch.load(\"model/MyModel_baseline_best.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": 8,
    "id": "JXFJ6oS8lRVX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.005, eps=1e-08) # YOUR OPTIMIZER\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # LOSS THAT YOU OPTIMIZE (SHOLD BE CROSS ENTROPY OR SMTH ELSE)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.97)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 9,
    "id": "CesoOl6BlRVY"
   },
   "source": [
    "Простой тест на проверку правильности написанного кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": 10,
    "id": "B_LB2jn6lRVY",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:10<00:00, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n",
      "0.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\n",
    "assert len(predicted_labels) == len(val_dataset)\n",
    "accuracy = accuracy_score(predicted_labels, true_labels)\n",
    "print(\"tests passed\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 11,
    "id": "tS-LLiXUlRVY"
   },
   "source": [
    "Запустить обучение можно в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": 12,
    "id": "ECIzZ_RYlRVZ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:09<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начальная точность: 33.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:14<00:00, 11.59it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 1;\t train loss: 2.506;\t valid loss: 2.898;\t Точность: 32.64 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:12<00:00, 11.79it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 2;\t train loss: 2.507;\t valid loss: 2.896;\t Точность: 32.86 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:13<00:00, 11.72it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 19.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 3;\t train loss: 2.502;\t valid loss: 2.901;\t Точность: 32.64 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:16<00:00, 11.45it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 4;\t train loss: 2.501;\t valid loss: 2.893;\t Точность: 32.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:12<00:00, 11.76it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 5;\t train loss: 2.504;\t valid loss: 2.890;\t Точность: 32.78 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:11<00:00, 11.93it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 6;\t train loss: 2.496;\t valid loss: 2.901;\t Точность: 32.88 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:12<00:00, 11.79it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 7;\t train loss: 2.501;\t valid loss: 2.899;\t Точность: 32.64 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:14<00:00, 11.63it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 19.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 8;\t train loss: 2.497;\t valid loss: 2.895;\t Точность: 32.69 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:11<00:00, 11.89it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 9;\t train loss: 2.496;\t valid loss: 2.896;\t Точность: 32.69 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:13<00:00, 11.70it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 10;\t train loss: 2.498;\t valid loss: 2.892;\t Точность: 32.87 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:12<00:00, 11.82it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 11;\t train loss: 2.489;\t valid loss: 2.890;\t Точность: 32.93 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:09<00:00, 12.05it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 12;\t train loss: 2.494;\t valid loss: 2.890;\t Точность: 32.90 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:10<00:00, 11.96it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 13;\t train loss: 2.489;\t valid loss: 2.893;\t Точность: 32.87 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:11<00:00, 11.89it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 14;\t train loss: 2.489;\t valid loss: 2.893;\t Точность: 33.03 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:15<00:00, 11.56it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 15;\t train loss: 2.486;\t valid loss: 2.898;\t Точность: 32.78 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:11<00:00, 11.91it/s]\n",
      "100%|██████████| 157/157 [00:08<00:00, 19.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 16;\t train loss: 2.488;\t valid loss: 2.888;\t Точность: 32.98 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:07<00:00, 12.29it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 17;\t train loss: 2.488;\t valid loss: 2.888;\t Точность: 33.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:55<00:00, 13.49it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 21.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 18;\t train loss: 2.486;\t valid loss: 2.900;\t Точность: 32.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:53<00:00, 13.73it/s]\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 19;\t train loss: 2.486;\t valid loss: 2.890;\t Точность: 33.04 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 772/1563 [00:55<00:57, 13.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, device, n_epochs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mНачальная точность: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m best_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m %\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# YOUR CODE\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m: \n\u001b[0;32m     63\u001b[0m         valid_loss, predicted, true \u001b[38;5;241m=\u001b[39m predict(model, val_dataloader, criterion, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_dataloader, criterion, optimizer, epoch_index, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_, y_ \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader):\n\u001b[0;32m     10\u001b[0m     x_train, y_train \u001b[38;5;241m=\u001b[39m x_\u001b[38;5;241m.\u001b[39mto(device), y_\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# перенос вычислений на GPU\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# делаем предсказание\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y_train) \n\u001b[0;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#x = x.view(x.size(0), -1)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_layers(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    440\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    441\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, val_dataloader, criterion, optimizer, scheduler, device, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model/my_model2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0 is 60.0 %\n",
      "Accuracy for class: 1 is 24.0 %\n",
      "Accuracy for class: 2 is 72.0 %\n",
      "Accuracy for class: 3 is 2.0 %\n",
      "Accuracy for class: 4 is 26.0 %\n",
      "Accuracy for class: 5 is 34.0 %\n",
      "Accuracy for class: 6 is 12.0 %\n",
      "Accuracy for class: 7 is 28.0 %\n",
      "Accuracy for class: 8 is 22.0 %\n",
      "Accuracy for class: 9 is 36.0 %\n",
      "Accuracy for class: 10 is 18.0 %\n",
      "Accuracy for class: 11 is 10.0 %\n",
      "Accuracy for class: 12 is 32.0 %\n",
      "Accuracy for class: 13 is 36.0 %\n",
      "Accuracy for class: 14 is 22.0 %\n",
      "Accuracy for class: 15 is 30.0 %\n",
      "Accuracy for class: 16 is 40.0 %\n",
      "Accuracy for class: 17 is 28.0 %\n",
      "Accuracy for class: 18 is 62.0 %\n",
      "Accuracy for class: 19 is 62.0 %\n",
      "Accuracy for class: 20 is 46.0 %\n",
      "Accuracy for class: 21 is 20.0 %\n",
      "Accuracy for class: 22 is 34.0 %\n",
      "Accuracy for class: 23 is 34.0 %\n",
      "Accuracy for class: 24 is 42.0 %\n",
      "Accuracy for class: 25 is 8.0 %\n",
      "Accuracy for class: 26 is 58.0 %\n",
      "Accuracy for class: 27 is 24.0 %\n",
      "Accuracy for class: 28 is 74.0 %\n",
      "Accuracy for class: 29 is 8.0 %\n",
      "Accuracy for class: 30 is 36.0 %\n",
      "Accuracy for class: 31 is 44.0 %\n",
      "Accuracy for class: 32 is 18.0 %\n",
      "Accuracy for class: 33 is 18.0 %\n",
      "Accuracy for class: 34 is 26.0 %\n",
      "Accuracy for class: 35 is 12.0 %\n",
      "Accuracy for class: 36 is 50.0 %\n",
      "Accuracy for class: 37 is 24.0 %\n",
      "Accuracy for class: 38 is 22.0 %\n",
      "Accuracy for class: 39 is 8.0 %\n",
      "Accuracy for class: 40 is 52.0 %\n",
      "Accuracy for class: 41 is 34.0 %\n",
      "Accuracy for class: 42 is 20.0 %\n",
      "Accuracy for class: 43 is 58.0 %\n",
      "Accuracy for class: 44 is 14.0 %\n",
      "Accuracy for class: 45 is 74.0 %\n",
      "Accuracy for class: 46 is 68.0 %\n",
      "Accuracy for class: 47 is 40.0 %\n",
      "Accuracy for class: 48 is 28.0 %\n",
      "Accuracy for class: 49 is 44.0 %\n",
      "Accuracy for class: 50 is 48.0 %\n",
      "Accuracy for class: 51 is 42.0 %\n",
      "Accuracy for class: 52 is 32.0 %\n",
      "Accuracy for class: 53 is 60.0 %\n",
      "Accuracy for class: 54 is 26.0 %\n",
      "Accuracy for class: 55 is 56.0 %\n",
      "Accuracy for class: 56 is 22.0 %\n",
      "Accuracy for class: 57 is 26.0 %\n",
      "Accuracy for class: 58 is 22.0 %\n",
      "Accuracy for class: 59 is 38.0 %\n",
      "Accuracy for class: 60 is 34.0 %\n",
      "Accuracy for class: 61 is 30.0 %\n",
      "Accuracy for class: 62 is 26.0 %\n",
      "Accuracy for class: 63 is 46.0 %\n",
      "Accuracy for class: 64 is 32.0 %\n",
      "Accuracy for class: 65 is 30.0 %\n",
      "Accuracy for class: 66 is 10.0 %\n",
      "Accuracy for class: 67 is 14.0 %\n",
      "Accuracy for class: 68 is 14.0 %\n",
      "Accuracy for class: 69 is 46.0 %\n",
      "Accuracy for class: 70 is 54.0 %\n",
      "Accuracy for class: 71 is 36.0 %\n",
      "Accuracy for class: 72 is 24.0 %\n",
      "Accuracy for class: 73 is 34.0 %\n",
      "Accuracy for class: 74 is 8.0 %\n",
      "Accuracy for class: 75 is 14.0 %\n",
      "Accuracy for class: 76 is 22.0 %\n",
      "Accuracy for class: 77 is 42.0 %\n",
      "Accuracy for class: 78 is 46.0 %\n",
      "Accuracy for class: 79 is 52.0 %\n",
      "Accuracy for class: 80 is 60.0 %\n",
      "Accuracy for class: 81 is 34.0 %\n",
      "Accuracy for class: 82 is 50.0 %\n",
      "Accuracy for class: 83 is 50.0 %\n",
      "Accuracy for class: 84 is 36.0 %\n",
      "Accuracy for class: 85 is 34.0 %\n",
      "Accuracy for class: 86 is 10.0 %\n",
      "Accuracy for class: 87 is 74.0 %\n",
      "Accuracy for class: 88 is 52.0 %\n",
      "Accuracy for class: 89 is 24.0 %\n",
      "Accuracy for class: 90 is 44.0 %\n",
      "Accuracy for class: 91 is 36.0 %\n",
      "Accuracy for class: 92 is 22.0 %\n",
      "Accuracy for class: 93 is 10.0 %\n",
      "Accuracy for class: 94 is 50.0 %\n",
      "Accuracy for class: 95 is 36.0 %\n",
      "Accuracy for class: 96 is 18.0 %\n",
      "Accuracy for class: 97 is 36.0 %\n",
      "Accuracy for class: 98 is 24.0 %\n",
      "Accuracy for class: 99 is 16.0 %\n",
      "Accuracy for class: 100 is 8.0 %\n",
      "Accuracy for class: 101 is 30.0 %\n",
      "Accuracy for class: 102 is 44.0 %\n",
      "Accuracy for class: 103 is 12.0 %\n",
      "Accuracy for class: 104 is 38.0 %\n",
      "Accuracy for class: 105 is 34.0 %\n",
      "Accuracy for class: 106 is 8.0 %\n",
      "Accuracy for class: 107 is 64.0 %\n",
      "Accuracy for class: 108 is 18.0 %\n",
      "Accuracy for class: 109 is 24.0 %\n",
      "Accuracy for class: 110 is 16.0 %\n",
      "Accuracy for class: 111 is 18.0 %\n",
      "Accuracy for class: 112 is 6.0 %\n",
      "Accuracy for class: 113 is 40.0 %\n",
      "Accuracy for class: 114 is 28.0 %\n",
      "Accuracy for class: 115 is 32.0 %\n",
      "Accuracy for class: 116 is 28.0 %\n",
      "Accuracy for class: 117 is 48.0 %\n",
      "Accuracy for class: 118 is 28.0 %\n",
      "Accuracy for class: 119 is 14.0 %\n",
      "Accuracy for class: 120 is 60.0 %\n",
      "Accuracy for class: 121 is 54.0 %\n",
      "Accuracy for class: 122 is 10.0 %\n",
      "Accuracy for class: 123 is 18.0 %\n",
      "Accuracy for class: 124 is 72.0 %\n",
      "Accuracy for class: 125 is 40.0 %\n",
      "Accuracy for class: 126 is 12.0 %\n",
      "Accuracy for class: 127 is 26.0 %\n",
      "Accuracy for class: 128 is 38.0 %\n",
      "Accuracy for class: 129 is 66.0 %\n",
      "Accuracy for class: 130 is 10.0 %\n",
      "Accuracy for class: 131 is 34.0 %\n",
      "Accuracy for class: 132 is 42.0 %\n",
      "Accuracy for class: 133 is 20.0 %\n",
      "Accuracy for class: 134 is 40.0 %\n",
      "Accuracy for class: 135 is 30.0 %\n",
      "Accuracy for class: 136 is 44.0 %\n",
      "Accuracy for class: 137 is 32.0 %\n",
      "Accuracy for class: 138 is 30.0 %\n",
      "Accuracy for class: 139 is 46.0 %\n",
      "Accuracy for class: 140 is 48.0 %\n",
      "Accuracy for class: 141 is 24.0 %\n",
      "Accuracy for class: 142 is 8.0 %\n",
      "Accuracy for class: 143 is 4.0 %\n",
      "Accuracy for class: 144 is 70.0 %\n",
      "Accuracy for class: 145 is 56.0 %\n",
      "Accuracy for class: 146 is 6.0 %\n",
      "Accuracy for class: 147 is 46.0 %\n",
      "Accuracy for class: 148 is 26.0 %\n",
      "Accuracy for class: 149 is 42.0 %\n",
      "Accuracy for class: 150 is 60.0 %\n",
      "Accuracy for class: 151 is 22.0 %\n",
      "Accuracy for class: 152 is 8.0 %\n",
      "Accuracy for class: 153 is 24.0 %\n",
      "Accuracy for class: 154 is 14.0 %\n",
      "Accuracy for class: 155 is 6.0 %\n",
      "Accuracy for class: 156 is 12.0 %\n",
      "Accuracy for class: 157 is 52.0 %\n",
      "Accuracy for class: 158 is 18.0 %\n",
      "Accuracy for class: 159 is 6.0 %\n",
      "Accuracy for class: 160 is 8.0 %\n",
      "Accuracy for class: 161 is 22.0 %\n",
      "Accuracy for class: 162 is 30.0 %\n",
      "Accuracy for class: 163 is 34.0 %\n",
      "Accuracy for class: 164 is 10.0 %\n",
      "Accuracy for class: 165 is 38.0 %\n",
      "Accuracy for class: 166 is 56.0 %\n",
      "Accuracy for class: 167 is 48.0 %\n",
      "Accuracy for class: 168 is 24.0 %\n",
      "Accuracy for class: 169 is 26.0 %\n",
      "Accuracy for class: 170 is 22.0 %\n",
      "Accuracy for class: 171 is 48.0 %\n",
      "Accuracy for class: 172 is 30.0 %\n",
      "Accuracy for class: 173 is 16.0 %\n",
      "Accuracy for class: 174 is 16.0 %\n",
      "Accuracy for class: 175 is 18.0 %\n",
      "Accuracy for class: 176 is 12.0 %\n",
      "Accuracy for class: 177 is 10.0 %\n",
      "Accuracy for class: 178 is 34.0 %\n",
      "Accuracy for class: 179 is 10.0 %\n",
      "Accuracy for class: 180 is 60.0 %\n",
      "Accuracy for class: 181 is 12.0 %\n",
      "Accuracy for class: 182 is 12.0 %\n",
      "Accuracy for class: 183 is 18.0 %\n",
      "Accuracy for class: 184 is 30.0 %\n",
      "Accuracy for class: 185 is 46.0 %\n",
      "Accuracy for class: 186 is 14.0 %\n",
      "Accuracy for class: 187 is 46.0 %\n",
      "Accuracy for class: 188 is 34.0 %\n",
      "Accuracy for class: 189 is 18.0 %\n",
      "Accuracy for class: 190 is 40.0 %\n",
      "Accuracy for class: 191 is 50.0 %\n",
      "Accuracy for class: 192 is 72.0 %\n",
      "Accuracy for class: 193 is 36.0 %\n",
      "Accuracy for class: 194 is 6.0 %\n",
      "Accuracy for class: 195 is 44.0 %\n",
      "Accuracy for class: 196 is 32.0 %\n",
      "Accuracy for class: 197 is 46.0 %\n",
      "Accuracy for class: 198 is 42.0 %\n",
      "Accuracy for class: 199 is 50.0 %\n"
     ]
    }
   ],
   "source": [
    "#all_losses, predictions, labels = predict(model, val_dataloader, criterion, device)\n",
    "\n",
    "classes = [x for x in range(200)]\n",
    "\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for images_, labels_ in val_dataloader:\n",
    "        images, labels = images_.to(device), labels_.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw01_part2_tony_upd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "max_cell_id": 35
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
